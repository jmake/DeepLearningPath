{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbc1698f-c390-437c-8641-ce64b9a9321f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 21 15:13:15 EDT 2025\n",
      "total 36\n",
      "drwxrwxrwx 1 jmake jmake   512 Mar 21 15:13 .\n",
      "drwxrwxrwx 1 jmake jmake   512 Mar 20 20:38 ..\n",
      "drwxrwxrwx 1 jmake jmake   512 Mar 21 13:59 .ipynb_checkpoints\n",
      "-rwxrwxrwx 1 jmake jmake 11716 Mar 21 13:56 04_agentic_rag_1a1.ipynb\n",
      "-rwxrwxrwx 1 jmake jmake 18740 Mar 21 15:13 04_agentic_rag_1b1.ipynb\n",
      "drwxrwxrwx 1 jmake jmake   512 Mar 20 20:56 ChromaDB\n",
      "drwxrwxrwx 1 jmake jmake   512 Mar 20 20:45 Data\n",
      "-rwxrwxrwx 1 jmake jmake     4 Mar 20 20:57 app_4.py\n",
      "-rwxrwxrwx 1 jmake jmake  2187 Mar 20 20:40 ingest_pdfs.py\n",
      "/mnt/d/z2025_1/AI/RAGs/Test4\n",
      "Python 3.12.6\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "date \n",
    "\n",
    "ls -la \n",
    "\n",
    "pwd\n",
    "\n",
    "python.exe --version \n",
    "\n",
    "ollama.exe list \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f0ab7ff-5d82-4ab3-937b-e76a9ff530fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "## Created '6709' chunks from 'Data/Blender43Manual.pdf' at './ChromaDB'\n",
    "#!python.exe ingest_pdfs.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8922921c-f652-4a50-af0d-ad80fec88a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95f8f80e-21e4-41e6-ac21-5b60518b9901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\z2025_1\\AI\\RAGs\\Env4\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_tokens': 5000, 'last_input_token_count': None, 'last_output_token_count': None, 'model_id': 'Qwen/Qwen2.5-Coder-32B-Instruct', 'provider': None}\n",
      "Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\n",
      "CPU times: total: 1.19 s\n",
      "Wall time: 1.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "## python.exe -m pip install langchain_ollama\n",
    "import smolagents\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "hf_token = \"\"\n",
    "model_id = \"Qwen/Qwen2.5-Coder-32B-Instruct\"\n",
    "\n",
    "engine = smolagents.HfApiModel(model_id=model_id, token=hf_token, max_tokens=5000)\n",
    "print( engine.to_dict() )\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": \"Hello, how are you?\"}]}]\n",
    "\n",
    "response = engine(messages, stop_sequences=[\"END\"])\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f601319-840a-49e3-8739-c8fd0e728124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02604f91-43d4-4e06-b553-cbb11847577e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">This agent has step_callbacks: they will be ignored by this method. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "This agent has step_callbacks: they will be ignored by this method. \u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tools', 'model', 'managed_agents', 'prompt_templates', 'max_steps', 'verbosity_level', 'grammar', 'planning_interval', 'name', 'description', 'requirements', 'authorized_imports', 'executor_type', 'executor_kwargs', 'max_print_outputs_length']\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 27.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import smolagents\n",
    "\n",
    "# Create the reasoner for better RAG\n",
    "reasoner = smolagents.CodeAgent(tools=[], model=engine, add_base_tools=False, max_steps=2)\n",
    "print( list(reasoner.to_dict().keys()) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a52b03-3a80-4236-967d-b7ded32c360a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24d66fdb-0fbb-4203-8c80-038067454202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6709\n",
      "CPU times: total: 31.8 s\n",
      "Wall time: 32.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "\n",
    "def split_documents_into_chunks( documents ) : \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len,\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def load_and_process_pdfs(data_dir: str) :\n",
    "    loader = DirectoryLoader(data_dir, glob=\"**/*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return split_documents_into_chunks(documents)\n",
    "\n",
    "\n",
    "data_dir = \"Data\"\n",
    "pdf_chunks = load_and_process_pdfs(data_dir)\n",
    "print( len(pdf_chunks) ) # 6709 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40672735-1676-4942-860c-0aa2d78cddf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39abcf2f-2e57-4990-a00e-9c01f30b67c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\z2025_1\\AI\\RAGs\\Env4\\Lib\\site-packages\\langchain_community\\document_loaders\\recursive_url_loader.py:43: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
      "\n",
      "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "\n",
      "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
      "\n",
      "    from bs4 import XMLParsedAsHTMLWarning\n",
      "    import warnings\n",
      "\n",
      "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
      "\n",
      "  soup = BeautifulSoup(raw_html, \"html.parser\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2102\n",
      "CPU times: total: 1.06 s\n",
      "Wall time: 2.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from langchain_community.document_loaders import RecursiveUrlLoader\n",
    "\n",
    "def load_and_process_html(url) :\n",
    "    loader = RecursiveUrlLoader(url)\n",
    "    docs = loader.load()\n",
    "    ## metadata = docs[0].metadata\n",
    "    ## page_content = docs[0].page_content[:]\n",
    "    return split_documents_into_chunks(docs)\n",
    "\n",
    "url = \"https://docs.python.org/3.9/\"\n",
    "html_chunks = load_and_process_html(url) \n",
    "print( len(html_chunks) ) # 2102 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2401d300-3e6f-4204-a8c4-0e0a4eff9c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "## pdf_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd64eaaa-bc20-4351-b4c8-9244a7261cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## python.exe -m pip install rank_bm25\n",
    "import smolagents\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "class RetrieverTool(smolagents.Tool):\n",
    "    name = \"retriever\"\n",
    "    description = \"Uses semantic search to retrieve the parts of transformers documentation that could be most relevant to answer your query.\"\n",
    "    inputs = {\n",
    "        \"query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The query to perform. This should be semantically close to your target documents. Use the affirmative form rather than a question.\",\n",
    "        }\n",
    "    }\n",
    "    output_type = \"string\"\n",
    "\n",
    "    def __init__(self, docs, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.retriever = BM25Retriever.from_documents(\n",
    "            docs, k=10\n",
    "        )\n",
    "\n",
    "    def forward(self, query: str) -> str:\n",
    "        assert isinstance(query, str), \"Your search query must be a string\"\n",
    "\n",
    "        docs = self.retriever.invoke(\n",
    "            query,\n",
    "        )\n",
    "        return \"\\nRetrieved documents:\\n\" + \"\".join(\n",
    "            [\n",
    "                f\"\\n\\n===== Document {str(i)} =====\\n\" + doc.page_content\n",
    "                for i, doc in enumerate(docs)\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18f629c3-c29f-4672-a25a-b96bd49d9524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.RetrieverTool object at 0x000001E85B166210>\n",
      "<smolagents.agents.CodeAgent object at 0x000001E85B165A60>\n",
      "CPU times: total: 234 ms\n",
      "Wall time: 228 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import smolagents\n",
    "\n",
    "pdf_retriever_tool = RetrieverTool(pdf_chunks)\n",
    "print( pdf_retriever_tool )\n",
    "\n",
    "pdf_agent = smolagents.CodeAgent(tools=[pdf_retriever_tool], model=engine, max_steps=2, verbosity_level=0)\n",
    "print( pdf_agent )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aa95cf8-14ba-427d-bd84-c50148bae802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Reached max steps.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;31mReached max steps.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output: 'Certainly! Here is the list of Principled BSDF Inputs based on the provided documents:\n",
      "\n",
      "1. Base Color\n",
      "2. Subsurface\n",
      "3. Subsurface Radius\n",
      "4. Subsurface Color\n",
      "5. Metallic\n",
      "6. Specular\n",
      "7. Specular Tint\n",
      "8. Roughness\n",
      "9. Anisotropic\n",
      "10. Anisotropic Rotation\n",
      "11. Sheen\n",
      "12. Sheen Tint\n",
      "13. Clearcoat\n",
      "14. Clearcoat Roughness\n",
      "15. IOR (Index of Refraction)\n",
      "16. Transmission\n",
      "17. Transmission Roughness\n",
      "18. Absorption Color\n",
      "19. Absorption Distance\n",
      "20. Scatter\n",
      "21. Scatter Radius\n",
      "22. Scatter Anisotropy\n",
      "23. Normal\n",
      "24. Clearcoat Normal\n",
      "25. Tangent\n",
      "\n",
      "These inputs are commonly used in rendering and computer graphics software, particularly in the Cycles render engine used by Blender.' \n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 24.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "query = \"List the Principled BSDF Inputs\"  \n",
    "pdf_agent_output = pdf_agent.run(query)\n",
    "print(f\"Final output: '{pdf_agent_output}' \") ## 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a211b3fb-8ecf-409e-b62d-1dac92708658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output: 'Bidirectional Scattering Distribution Function' \n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 9.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "query = \"Waht is the meaning of BSDF?\"\n",
    "pdf_agent_output = pdf_agent.run(query)\n",
    "print(f\"Final output: '{pdf_agent_output}' \")  ## Bidirectional Scattering Distribution Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2c76858-5183-4f3a-b128-d9128c25a23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## html_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dd1eb5d-a4c8-4211-b882-4628b687ffe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.RetrieverTool object at 0x000001E836D57D70>\n",
      "<smolagents.agents.CodeAgent object at 0x000001E85B241310>\n",
      "Final output: '['Cython', 'cffi', 'SWIG', 'Numba']' \n",
      "CPU times: total: 2.23 s\n",
      "Wall time: 12.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import smolagents\n",
    "\n",
    "html_retriever_tool = RetrieverTool(html_chunks)\n",
    "print( html_retriever_tool )\n",
    "\n",
    "html_agent = smolagents.CodeAgent(tools=[html_retriever_tool], model=engine, max_steps=2, verbosity_level=0)\n",
    "print( html_agent )\n",
    "\n",
    "query = \"Recommended third party tools for 'Extending and Embedding the Python Interpreter' mentioned in these documents\"  \n",
    "html_agent_output = html_agent.run(query)\n",
    "print(f\"Final output: '{html_agent_output}' \") ## 4,  Cython, cffi, SWIG and Numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ae05b7-65d9-42af-9f6e-8c2ecb4d7e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37284201-9d8e-496f-a7d8-6972f556d080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 21 15:14:39 EDT 2025\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "## jupyter-nbconvert.exe --to notebook --execute .\\agentic_rag_1a1.ipynb --output executed_notebook.ipynb\n",
    "date "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
